apiVersion: v1
kind: Pod
metadata:
  name: mlinference
  namespace: test-mlperf
spec:
  restartPolicy: OnFailure
  containers:
    - name: inference
      image: "quay.io/eldritchjs/mlperf-inference-nvidia:updated"
      command: ["/bin/bash", "-ec", "cd /work; tail -f /dev/null " ]
      runAsUser: 1000
      env:
        - name: NVIDIA_VISIBLE_DEVICES
          value: all
        - name: NVIDIA_DRIVER_CAPABILITIES
          value: "compute,utility"
        - name: NVIDIA_REQUIRE_CUDA
          value: "cuda>=5.0"
      securityContext:
        privileged: true
      resources:
        limits:
          nvidia.com/gpu: 1 # requesting 1 GPU
